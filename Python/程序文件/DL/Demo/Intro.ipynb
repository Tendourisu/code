{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os \n",
    "# set available GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 矩阵与张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5.0, 6],\n",
    "        [7, 8, 9]\n",
    "    ]\n",
    ")\n",
    "print(x.shape, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "y = torch.Tensor(\n",
    "    [\n",
    "        [1, 2, 3],\n",
    "        [4, 5, 6],\n",
    "        [7, 8, 9]\n",
    "    ]\n",
    ")\n",
    "print(y.shape, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64 torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(x.dtype, y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(\n",
    "    [\n",
    "        [\n",
    "            [1, 2, 3],\n",
    "            [4, 5, 6],\n",
    "            [7, 8, 9],\n",
    "        ],\n",
    "        [\n",
    "            [1, 2, 3],\n",
    "            [4, 5, 6],\n",
    "            [7, 8, 9],\n",
    "        ]\n",
    "    ]\n",
    "    \n",
    ")\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.],\n",
      "          [0.],\n",
      "          [0.]],\n",
      "\n",
      "         [[0.],\n",
      "          [0.],\n",
      "          [0.]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.zeros(1, 2, 3, 1)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2780],\n",
      "          [0.4346],\n",
      "          [0.2693]],\n",
      "\n",
      "         [[0.0056],\n",
      "          [0.2510],\n",
      "          [0.8040]]]])\n",
      "tensor([[[[-0.1007],\n",
      "          [-0.6169],\n",
      "          [-0.2226]],\n",
      "\n",
      "         [[ 2.0239],\n",
      "          [ 0.5620],\n",
      "          [-0.0897]]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(1, 2, 3, 1)\n",
    "x = torch.rand(1, 2, 3, 1)\n",
    "print(x)\n",
    "x = torch.randn([1, 2, 3, 1], device=\"cuda:0\", requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四则运算与矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x tensor([[[ 1.7883,  1.8412],\n",
      "         [ 0.4796,  0.3216]],\n",
      "\n",
      "        [[ 1.3055,  1.3130],\n",
      "         [-0.1197,  0.1863]]])\n",
      "y tensor([[[-1.7623, -0.3706],\n",
      "         [-1.7623, -0.3706]],\n",
      "\n",
      "        [[-1.8145,  0.4805],\n",
      "         [-1.8145,  0.4805]]])\n",
      "z tensor([[[ 0.0260,  1.4707],\n",
      "         [-1.2827, -0.0489]],\n",
      "\n",
      "        [[-0.5091,  1.7935],\n",
      "         [-1.9342,  0.6668]]])\n",
      "a tensor([[[ 3.5506,  2.2118],\n",
      "         [ 2.2419,  0.6922]],\n",
      "\n",
      "        [[ 3.1200,  0.8325],\n",
      "         [ 1.6948, -0.2942]]])\n",
      "b tensor([[[-3.1516, -0.6823],\n",
      "         [-0.8452, -0.1192]],\n",
      "\n",
      "        [[-2.3689,  0.6309],\n",
      "         [ 0.2172,  0.0895]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 2, 2)\n",
    "print('x', x)\n",
    "y = torch.randn(2, 2)[::, None].expand(2, 2, 2)\n",
    "print('y', y)\n",
    "z = x + y\n",
    "print('z', z)\n",
    "a = x - y\n",
    "print('a', a)\n",
    "b = x * y\n",
    "print('b', b)\n",
    "c = x / y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/tmp/ipykernel_3561188/3335689457.py\", line 2, in <module>\n",
      "    print(l + x)\n",
      "RuntimeError: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 2\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1055, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(record))\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 955, in format_record\n",
      "    frame_info.lines, Colors, self.has_colors, lvals\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 778, in lines\n",
      "    return self._sd.lines\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/stack_data/core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/stack_data/core.py\", line 677, in included_pieces\n",
      "    scope_pieces = self.scope_pieces\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/stack_data/utils.py\", line 145, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/stack_data/core.py\", line 614, in scope_pieces\n",
      "    scope_start, scope_end = self.source.line_range(self.scope)\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/stack_data/core.py\", line 178, in line_range\n",
      "    return line_range(self.asttext(), node)\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/executing/executing.py\", line 333, in asttext\n",
      "    self._asttext = ASTText(self.text, tree=self.tree, filename=self.filename)\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/asttokens/asttokens.py\", line 305, in __init__\n",
      "    super(ASTText, self).__init__(source_text, filename)\n",
      "  File \"/home/yuliu/anaconda3/envs/AGI/lib/python3.8/site-packages/asttokens/asttokens.py\", line 47, in __init__\n",
      "    source_text = six.ensure_text(source_text)\n",
      "AttributeError: module 'six' has no attribute 'ensure_text'\n"
     ]
    }
   ],
   "source": [
    "l = torch.zeros(2, 3)\n",
    "print(l + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 矩阵乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n",
      "torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(4, 3)\n",
    "print(y.T.shape)\n",
    "z = x @ y.T  # ab bc -> ac\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "z1 = torch.matmul(x, y.T)\n",
    "print(z == z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 2, 3)\n",
    "y = torch.randn(5, 3, 4)\n",
    "z = x @ y\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 5, 2, 3)\n",
    "y = torch.randn(2, 5, 4, 3)\n",
    "# z = x @ y.T\n",
    "# z = x @ y.permute(0, 1, 3, 2)\n",
    "# z = x @ y.transpose(2, 3)\n",
    "z = x @ y.transpose(-1, -2)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 5, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "z = torch.einsum('bcij,bckj->bcik', x, y)\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 自动微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2.],\n",
      "        [2., 2., 2.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "x.requires_grad_(True)\n",
    "y = (x * 2).sum()\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn([2, 3], requires_grad=True)\n",
    "y = torch.randn([3, 4], requires_grad=True)\n",
    "z = x @ y\n",
    "l = z.sum()\n",
    "l.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4454,  1.1645, -0.1907],\n",
      "        [-0.4454,  1.1645, -0.1907]])\n",
      "tensor([[-2.5393, -2.5393, -2.5393, -2.5393],\n",
      "        [ 0.4827,  0.4827,  0.4827,  0.4827],\n",
      "        [ 1.6783,  1.6783,  1.6783,  1.6783]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)\n",
    "print(y.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  1.595448613166809\n",
      "loss:  1.3521206378936768\n",
      "loss:  1.1732923984527588\n",
      "loss:  1.0404361486434937\n",
      "loss:  0.940604567527771\n",
      "loss:  0.8646981120109558\n",
      "loss:  0.8062798380851746\n",
      "loss:  0.7607654333114624\n",
      "loss:  0.7248649597167969\n",
      "loss:  0.6961988806724548\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "model = nn.Linear(5, 2)\n",
    "\n",
    "x = torch.randn(10, 5)\n",
    "y_target = torch.randn(10, 2)\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)  \n",
    "  \n",
    "for epoch in range(10):  \n",
    "    optimizer.zero_grad()  \n",
    "    y = model(x)\n",
    "    loss = criterion(y, y_target)  \n",
    "    loss.backward()  \n",
    "    optimizer.step()\n",
    "    print(\"loss: \", loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0945fb9c50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.datasets import CIFAR10, MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28]) torch.Size([32])\n",
      "tensor([2, 7, 3, 1, 6, 7, 1, 6, 6, 0, 3, 9, 7, 2, 9, 6, 4, 9, 9, 1, 8, 7, 5, 8,\n",
      "        2, 5, 3, 8, 1, 6, 3, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "# dataset_train = CIFAR10(root='./data', train=True, transform=ToTensor(), download=True)\n",
    "# dataset_test = CIFAR10(root='./data', train=False, transform=ToTensor(), download=True)\n",
    "dataset_train = MNIST(root='./data', train=True, transform=ToTensor(), download=True)\n",
    "dataset_test = MNIST(root='./data', train=False, transform=ToTensor(), download=True)\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)\n",
    "\n",
    "for x, y in tqdm(dataloader_train):\n",
    "    print(x.shape, y.shape)\n",
    "    print(y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        # self.fc = nn.Linear(32 * 32 * 3, 10)\n",
    "        self.fc = nn.Linear(28 * 28, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "# Define training and testing loop\n",
    "def train(model, dataloader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # training loop\n",
    "    for epoch in range(5):\n",
    "        for x, y in tqdm(dataloader):\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\"loss: \", loss.item())\n",
    "\n",
    "def test(model, dataloader):\n",
    "    acc = 0\n",
    "    for x, y in tqdm(dataloader):\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "        y_pred = model(x)\n",
    "        acc += (y_pred.argmax(dim=1) == y).float().mean().item()\n",
    "    print(\"acc: \", acc / len(dataloader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:07<00:00, 264.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.3949453830718994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:05<00:00, 360.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.32440489530563354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:05<00:00, 362.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.3008139729499817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:05<00:00, 325.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.3084794580936432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:05<00:00, 360.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.23537926375865936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 444.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.924620607028754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = MyModel().cuda()\n",
    "train(model, dataloader_train)\n",
    "test(model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:08<00:00, 208.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.18687574565410614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:07<00:00, 239.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.17335914075374603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:07<00:00, 244.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.07729557156562805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:06<00:00, 269.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.08850011974573135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:09<00:00, 198.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.00430353032425046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 244.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9719448881789138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            # nn.Linear(32 * 32 * 3, 64),\n",
    "            nn.Linear(28 * 28, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "    \n",
    "model = MyModel().cuda()\n",
    "train(model, dataloader_train)\n",
    "test(model, dataloader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1875 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:14<00:00, 125.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.005114540457725525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:14<00:00, 132.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0012219055788591504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:15<00:00, 124.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0006020505679771304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:14<00:00, 131.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.0022100345231592655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1875/1875 [00:13<00:00, 137.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  8.376239566132426e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 204.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9896166134185304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# conv model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # nn.Conv2d(3, 16, 3, padding=1),\n",
    "            nn.Conv2d(1, 16, 3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            # nn.Linear(64 * 8 * 8, 64),\n",
    "            nn.Linear(64 * 7 * 7, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "model = MyModel().cuda()\n",
    "train(model, dataloader_train)\n",
    "test(model, dataloader_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AGI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
